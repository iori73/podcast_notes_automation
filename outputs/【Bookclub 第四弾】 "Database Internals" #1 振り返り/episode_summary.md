## **基本情報**

- Spotify URL：[エピソードリンク](https://open.spotify.com/episode/5t8CNshfrjpwAFjGLAuYQF?si=BFAEYusKTfWz8JJJQhVwaw)
- 公開日：2025年01月25日
- 長さ：23:03

## **要約**

Rondo Tech Talkのけんわが妻が2025年の新しいエピソードについて話しています。今回はBook Clubの一環でDatabase Internalsを取り上げ、第1回のチャプター1 Introduction and Overviewに焦点を当てる内容です。振り返り収録を通じて、本の内容や盛り上がった議論について深く掘り下げていきます。リスナーには、実際にBook Clubに参加した方や非同期で参加している方を想定しており、Book Clubに参加していない方でも共通の知識を共有することができます。このエピソードでは第1章のイントロダクションと概要に焦点を当てており、データベースマネジメントシステム（DBMS）の概要やデータの保存方法、メモリベースとディスクベースのDBMSの比較などについて議論されます。次回以降のエピソードでは、データ構造やインプリメンテーションなどの詳細な内容にも触れる予定です。Book Clubに参加している方やデータベースに興味がある方にとって、興味深い内容となっていますので、ぜひお楽しみください。

## **目次**

00:01 Book Club 第4弾の紹介と目的
01:07 振り返り収録のリスナー層と内容
03:11 DBMSの機能とデータベースの構成要素
05:18 データベースの保存方法
07:04 DBMSの種類
07:59 インデックスについて
09:58 データベースのインデックスに関する必要性
11:26 DBMSにおける裏側の仕組みとプロダクトの分類
12:34 新しい研究トピック: NVMを利用したDBMS
14:25 技術メモとディスカッション
14:48 データベースエンジニアリングにおけるディスクレイアウトの重要性
18:46 再現環境の構築とデータファイル・インデックスファイルの理解
19:00 PostgreSQLの学習方法
19:47 ハンズオン学習の重要性
21:53 B-Treeの基本とディスクベースDBMSでの利用

## **文字起こし**

Listenerのみなさん こんにちは Rondo Tech Talkのけんわが妻です 今日はですね 2025年始まりまして Book Club 第4弾 Database Internalsをやってるんですけれども その第1回チャプター1 Introduction and Overviewを読んだ振り返り収録というのをやっていきたいと思います 2025年もですね Book Club第4弾 できれば第5弾2つやっていきたいなと思っていて 振り返り収録も引き続きやっていこうと思ってます 時々今回のようにソロ収録で録ったり 時々ゲストの方を呼んで 2人3人で録ったりして チャプターごとにやっていこうかなと思ってます この振り返り収録の想定リスナーとしてはですね 大体スターパターンかなと思ってます 第1パターンとしては Book Clubの参加者の方が実際に参加した後とか あと今回は非同期で参加するタイムゾーンもあるので 同期で参加できなかった方が聞いて 記憶の定着じゃないですけれども 具体的に盛り上がった議論の内容であったり コンテンツの本の内容をもう1回振り返ることで 新しい観点をもう1回再発見したりとか より深く理解するきっかけになればいいかなと思ってます 想定リスナーの2つ目のパターンがですね London Tech Talk こうしてBook Club第4弾となると 収録に合わせて Book Clubには参加しないんですけれども リスナーの方の中で一緒に本を読んでくれているという方が 結構いらっしゃるということを耳にしたので その方々とも一緒に各州で今Book Clubやってるんですけれども なるべくそれにキャッチアップする形で 振り返り収録を発信していこうと思うので データベースインターナルズを読んでいる方は ぜひこの振り返り収録を1つマイルストーンというか 定期的なハードビートみたいな感じで 2週間に1回目標として配信していくので 一緒に読み進めていただけるきっかけになれば いいかなと思ってます 基本的には個人的なTLDRとか あとは記憶に残っているキーワードや Book Clubの中で盛り上がった観点について 紹介していこうと思います 逆に言うと本の内容をまるっと紹介するわけでは もちろんないので 内容が気になる方はぜひ本を買って 一緒に読んでいっていただければなと思います ということで今回の第1章は イントダクション&オーバービューということで 感想を聞いてみても割と第2章 第3章 第4章となってくると データベースを作るB3のデータ構造の計算量ですとか 具体的なインプリメンテーションですとか 細かいところに入っていく前の準備段階として DBMSのジェネラルな話 ハイレベルな話というのが多かったように思います まずそもそもDBMS データベースマネジメントシステムとは何ですかというところで 今までデータベースを開発したことがない でもSQLは書いたことあるよとか データベースについて何となく聞いたことある みたいなのも想定読書に入っているので そういった方向けにまずそもそも DBMSがしていることは何かということで DBMSというのはこういうものだよという 説明があったりしましたね ここら辺は割とハイレベルであったものの ネットワークを通じてSQLが発行されて クエリを解釈するクエリプロセッサーがいて クエリの内容を実際に実行する エグゼキューションエンジンというのもいて そのデータを実際に格納しているディスクが メモリから読み出すストレージエンジンという コンポーネントたちがいて 今までデータベースをユーザーとして使っていると SQLを発行したら 何かいい感じにゴニョゴニョして データを返してくれるというところだったんですけれども そのSQLを投げて結果が来るまでの裏側で トランスポートとかクエリプロセッサー エグゼキューションエンジンとかストレージエンジン みたいなコンポーネントがあるということを 理解できるというのが一つ目のゴールかなと思っています 例えばSQLのパフォーマンスがいまいち出ないなとか スロークエリが出るなというときに 実際どういうクエリプランが 実行されているかということで 例えばXプレーンを実行して どういった実行計画にされるかみたいな パフォーマンス改善の一環でやったことが ある方もいるかもしれないですけれども それはDBMSのアーキテクチャでどういうことなのか クエリプロセッサーまでは到達しているけれども 実際にエグゼキューションエンジンを実行することがな 結果を返しているんだなみたいなことが分かると Xプレーンが実際に何をしているかというのも 今後も理解できるかなと思っていたりします DBMSのアーキテクチャをざっくり押さえた上で この第一章でポイントになっていた観点が 大まかに言うと三つありますね まず一つ目がデータベースというのは データを保存するものですけれども データをどこに保存するかということで基本的にはディスクベースとDBMSですが、メモリにデータを保存するメモリベースのDBMSがあります。 メモリベースのDBMSとディスクベースのDBMSではどういった違いがあるかを理解しました。 運用コストやハードウェアの購入コスト、マシンがクラッシュした時にデータが揮発するかどうか、 そういったいくつかの観点においてメモリベースのDBMSとディスクベースのDBMSではこんな違いがあるということを理解しました。 ここらへんはメモリとかディスクとかを踏まえた上で、 普段自分たちが使っているDBMSがどっちの派閥に属するのかであったりとかということを踏まえながら理解できたかなと思います。 2つ目はDBMSにもいくつかあります。 マイシークレとかポスクレみたいなローオリエンティット、日本語でいうと列指向ですね。 行列の列ですね。列指向のDBMS。それから行指向のカラムオリエンティットDBMSであったりとか、 あとワイドカラムストレージと呼ばれるDBMSもあり、それぞれのざっくりとした違いについても理解しました。 ここらへん結構カラムオリエンティットDBMSという言葉を初めて聞いたという方であったり、 ワイドカラムストレージについて詳しく調べてみたよという方もいらっしゃったりしたので、 結構新しいキーワードとなって何かしらテイクアウエーがある方も多かったんじゃないかなと思います。 あとは第2章からですね、ビズリとかインデックスの詳細に入っていくんですけど、 そもそもインデックスって何という話がありました。 データファイルVSインデックスファイルのところでは、データファイル、データベースに保存するデータ本体を PostGreater Heapと言ったりしますけれども、保存するデータファイルというものと、 あとパフォーマンスを向上させるためにインデックスというものを作ったことがある方も多いと思うんですけども、 インデックスファイルというのは具体的には何なのかというところを理解しました。 例えばインデックスを作るということは、データファイルを作品のように、 本のアナロジーで考えると分かりやすいんですけども、 例えば辞書とかをイメージしていただくと分かるんですけど、 実際の単語について書かれている本の内容自体のところがデータファイルだとすると、 例えばPagesとか新しい単語を調べているとすると、 Pのところまでページをめくって探さなきゃいけないですよね。 でももし作品インデックスというのがあれば、一気にページ数まで飛べますと。 このポイントは作品インデックス自体というのも形を変えた別のデータという点である。 ことがここを読んで分かったかなと思います。 本も実際に辞書とかもそうなんですけども、作品だけで辞書とかってなると数十ページ、 百数十ページぐらいの実際のページボリュームを使ったりしますよね。 なのでこれが分かると具体的にどういうことが分かるかというと、 例えばSQLのリードパフォーマンスを上げるためにインデックスを作ればいいということは、 SQL 101みたいなすごいビギナーズレッスンとかであると思うんですけども、 インデックスを作りまくればいいわけではないということが、 裏側の仕組みを踏まえた上で理解できたかなと思います。 そのインデックスを例えば作りまくると、それは実際インデックスのサイズも必要となってくるわけなので、 インデックスを作れば作るほど、インデックス用のディスクサイズというのが必要になってきたりしますし、 あとはインデックス自体を更新しなきゃいけないですよね。 例えば辞書のアナロジーにまた戻りますけど、 例えば辞書を作りますと、インデックスを作ります。 辞書の世界もそうですけど、第一版、第二版、第三版というふうに新しい単語が出てきたり、 もう使われなくなった単語を削除したりとか、 あとは新しい意味を加えたりアップデートしたりとか、 あとは若者が使う新しい言葉を入れたりクリエイトしたりとか、 というケースは出てくると思います。 そのために作品も更新しなくちゃいけないんですよね。 データベースも同じなので、本体に更新があるたびにインデックスも更新されます。 そのために更新しなくちゃいけません。 つまりインデックスを作れば作るほど、ライトのパフォーマンスにも影響していく可能性があります。 なのでリードのパフォーマンスを上げるためにインデックスを作る。 ただ一方でインデックスのためによりサイズが必要となってきたりとか、 ライトへのパフォーマンスへの影響があるということも、 この章を読んで裏側の仕組みから理解できたんじゃないかなと思います。 ということで、今回はDBMSの裏側の仕組みに入る前に、 すごいハイレベルでDBMSが普段SQLを発行したら結果を返してくれるまで、 どのように裏側で頑張ってくれているのかであったりとか、 あとその世の中にいろんなプロダクトがありますよね。 MongoDBとかGoogle SpannerとかBigtableとかRedshiftみたいな、 それらを分類するときに、 ローオリエンティット、列子庫とか行子庫とか、あとワイダー絡むなストレージとか、 いろんな見方があるよということを理解したり、 あとはインデックスというのも裏側の仕組みで見ると、 具体的にはどういうことなのかというのをこの章を読んでですね。今回初回だったという事もあって内容はハイレベルだったんですけど 読書面もですね結構盛り上がりましたね 個人的にもその新しいキーワードとかいくつかテイクアウエーがありました 個人的に気になったのはですね 本書の中でも軽くキーワードとして触れられてたのかな 最近の新しめの研究としては 本書ではメモリベースとかディスクベースとかっていう話がありましたけれども nvm ノンバラタイルメモリーという 揮発しないメモリー上にDBMSを置いたらどうなるのかということで結構論文が出ていたりだとか あとはその他の本とかでも記載があったりするんですけれども そこについてちょっと調べてみたいなと思いました それについて触れてくださった参加者がいたんですけども 僕は現時点で nvm ベースの DBMS についてあまり詳しくないので それは一つテイクアウエーかなと思いましたね やっぱり参加者の方それぞれによって今使っているデータベースが全然違いますと 僕は例えば会社では MySQL 使ってたりとか Bigtable 使ってたりしますけれども POSGREを使っている方もいれば AWS DynamoDB みたいなドキュメントベース志向のデータベースを使っている方もいますし あとは僕が全然聞いたことないようなデータベースを使っている方もいますし ストリーミングとかでいろんな形で DBMS を使っている方もいるので そのバックグラウンドがすごい多様なのはすごい良かったなと思います なので普段自分が使っているデータベースの経験を踏まえた上でのコメントとか疑問とか あとは他の人と比較検討しながら 他の人が使っているプロダクトとの違いというところに着目して より理解が含められたんじゃないかなと思います 結構ここでつまずいたポイントで多かったのはそうですね まず DBMS アーキテクチャのところは割と理解した方が多くて カラムアオリエンテッドデータベースのところの使いどころ これについてキーワードを始めて聞いた方とかは 具体的にどういった使いどころがあるのかなというところについても ディスカッションポイントがあったりしましたね あとはやっぱりインデックスファイルが具体的には何物なのか 検索を効率化するということは聞いていたけれども 具体的にディスク上でどういうレイアウトになっているかというのをざっくりイメージできたのは 第2章第3章につながっていくかなと思います 今回個人的にちょっとワクワクしているのはですね フロントエンジニアとかモバイルエンジニアの方も参加してくれていて モバイルでも例えば僕の理解が正しければSQLiteのハバツーみたいなのを動かしてたりすると思うんですけど 各デバイス上での最新のDBMSの事情であったりとか 具体的に普段の開発でどのようなことを気をつけているのかとか あとはリモート側のデータベースの自動新規みたいなファイアベースとかも提供していたりしますけれども そこら辺の最近の状況についてキャッチアップできたりするといいかなと思ってたりしますね あとはOTLP OLAP あとはそれの発生としてHTAPというのがあって そこら辺のキーワードについて調べましたという方もいらっしゃいましたね LTPというのがオンライントランザクションプロセッシングデータベースかな OLAPというのがよりどっちかというと分析とかレポート作成に強みを置いている オンラインアナリティカルプロセッシングデータベースですね HTAPというのがそれのハイブリッドという形で 例えば具体的に言うとOTLPは業種が多いですね MySQLとかPoSQLですけれども OLAPだと例えばビッグクエリとか分析用のデータベースレッドシフトとかあったりしますけれども そこら辺について自分が知っているプロダクトがどっちなのかという観点で 考えてみた方も何かいらっしゃいました そんなところかな あとは内容としてはそこまで突っ込んだものではなかったので 本書の中でもイントロの章なので読みやすかった方も多かったんじゃないかなと思います 個人的には今回のデータベースインターナルズの参加者募集の収録というのも 過去に去年の末に公開したところでも結構ブッククラブ自体の運営に対する方針とか工夫とか 自分の思いみたいについて語ったので ちょっとそこについてはすべてはリピートしないんですけれども 今回実際始まってみてやっぱり良かったなと思うのは 第3回目と違って一つのタイムゾーンというか 一つのチームをタイムゾーン回してやっていくぞという風にしたので やっぱりその前回と違って一つのチームでやってるぞみたいな感じで すごい議論もディスコードも含めてちょっと盛り上がり始めているなというところもありますし やっぱりその今までは他の参加者のゲストの収録とかを聞いて 名前も知ってたしディスコードでも絡んでたことはあったけど 初めてミーティングで顔合わせて嬉しかったですみたいなフィードバックとかもらえたりしたので そういう意味で今回形を変えたのは良かったかなと思います 何回か回数を重ねるにつれて課題とかも見えてくるのでとりあえず第一回やってみて、狙った効果は出たし、いいフィードバックをもらえたかなと思います。 その技術メモも相変わらず事前に質問があったりとかコメントがあったりして結構盛り上がっているので、 僕個人もスレッドで議論したりとかディスコードで貼ってくれた新しいリンクを見たりすることで結構キャッチアップしたり、 記憶を新しくリフレッシュさせたりというところもあるので、すごい自分として学んでいますね。 今回個人的にやってて良かったなと思うのは、手元で再現環境を作りながらやってみるということですね。 例えば今回はデータファイル図とかインデックスファイルの話があって、 インデックスの仕組みとか動きについて結構詳しくやっていくと思うんですよね。 そこを深く理解するためには、例えば自分が使っているデータベース、 例えばPostgreだったらGitHubとかでオープンソースの実装を見てみるとか、 あとはGPTにリファレンス実装を書いてもらってそれを理解するという、 そういったやり方もあると思いますし、 例えばインデックスでいうと手元にPostgreを動かしたりとか、 あとはスーパーベースみたいなある程度フリーで使えるソフトウェアザーサースの PostgreとかMySQLがクラウドで動いている環境を作っちゃって、 そこで適当なテーブルを作っていろんなインデックスを作って実行計画を見てみるとか、 そういったやり方をしながらハンズオンも適度に絡めながらやっていけるといいかなと思います。 第2章、第3章となっていくとB-Treeの細かい動きになっていくんですけれども、 もしかしたらデータ構造、アルゴリズムあたりを勉強したことがある方は、 その機構造についてベースの知識があるかもしれないんですけれども、 そうじゃない方とかは、例えばまずBSD、Binary Search Treeを 自分の好きなプログラミング言語で書いてみたりとか、 リートコードスタイルでB-Treeのノードスプリットとノードマージについて書いてみるとか、 そういうやり方もありかなと思っています。 これも取っ掛かりは、GPTとかに聞くといい感じのクエスチョンを作ってくれるんですね。 例えば、プロンプトの例として、 データベースインターナル図を読んでいてB-Treeに理解したいですと、 インタビュースタイル形式でノードスプリットとノードマージについてのクエスチョンを生成してくださいみたいな感じにすると、 程よいスコープのクエスチョンを生成してくれたりするので、それに合わせて、 プログラミング言語指定すると簡単にユニットテストとかも合わせて書いてくれたりするので、 それに合わせてコードスクリプトを書いてみたりとかすると、 より深く理解できるんじゃないかなと思っています。 個人的には、この本を読みながら最新の情報もキャッチアップしたくて、 過去に読んだけどうまく読み切れてなかった、 例えばスパナの論文とか、これはちょっと古かったりしますけど、 2006、7年くらいかな。 例えば論文を改めて読み返してみたりとか、 あとは先ほどもちょっと触れましたけれども、 ノンボラタイルメモリーベースのDBMSについて今はどういう状況なのかなというのとか、 外部の論文、この本書に載せられていないようなアップデートのされた情報とかも見ながら、 Book Clubの内容にコントリビューションできたらいいかなと思っています。 ということで、第一章の振り返りを簡単にしました。 第二章はB-Tree Basicということで、 そもそもB-Treeって何よ、みたいなところをやっていきます。 第二章の目的は、 ローベースがDBMSではB-Treeを使うことが多いです。 Postgreでも使っているしMySQLでも使っているんですけども、 なぜディスクベースのDBMSでB-Treeが好まれるのかを理解するというのが一つのゴールかなと思っているので、 これから二章を読む方はぜひ、 なぜB-TreeがディスクベースのDBMSで使えるのかを 説明できるようになると一つ目標達成かなと思うので、 ぜひその観点を頭に入れて読んでみてください。 はい、ということで今回は Rhodo Tech Talk Book Club第4弾、 データベースインターナルズ第一章の振り返りでした。 ありがとうございました。 ご視聴ありがとうございました。

## **English Summary**

## **Transcription**

In this episode of the Rondo Tech Talk, Kencho and his wife discuss Chapter 1 of the Book Club's newest episode for 2025: Database Internals. They dive into the content of the book and the discussions that took place, through a retrospective recording. The episode is designed for both Book Club members and those participating asynchronously, and it provides a shared understanding for those who did not attend the Book Club. This episode focuses on the Introduction and Overview from Chapter 1, discussing the fundamentals of Database Management Systems (DBMSs), how data is stored, and a comparison of memory-based and disk-based DBMSs. Future episodes will cover more detailed topics such as data structures and implementations. For those participating in the Book Club or interested in databases, this is an engaging episode that you won't want to miss.


## **English Transcription**

## **Transcript**

Hello, listeners. This is Ken-wa Yoneyama from Rondo Tech Talk. We started the fourth season of our Book Club in early 2025, and I'd like to share our reflection on the first chapter, "Introduction and Overview," of the book _Database Internals_. Our goal for 2025 is to complete the fourth and possibly the fifth seasons of our Book Club. We'll continue to record these reflection sessions. Sometimes we'll have solo recordings like this one, and sometimes we'll invite guests to join us for two- or three-person recordings. We plan to cover each chapter in this way. I'm targeting our listeners who are roughly following our star pattern. The first pattern is intended for participants of the Book Club who want to review the content or had to participate asynchronously due to different time zones. The discussions we had, the main points of the content, and new perspectives we gained from the discussions will help you reinforce your memory. The second pattern of expected listeners is for those who follow London Tech Talk. While they may not participate in the Book Club, I've heard that many of our listeners read the book along with us. I'd like to provide a recap for those who are also working through the Book Club. For those who are reading _Database Internals_, I hope these reflections will serve as a milestone or a regular heartbeat. We aim to release these reflections every two weeks, so we can all stay on track with our reading. I'll provide key takeaways, memorable keywords, and intriguing perspectives that were discussed in our Book Club. I won't go over the entire contents of the book, so if you're interested in the details, I encourage you to read it yourself. Our first chapter was titled "Introduction & Overview." From the feedback I've received, I believe that Chapters 2, 3, and 4 will delve into specific details, such as data volume computations for B-tree creation and specific implementations. The first chapter seems to focus on broader concepts, providing a foundation before getting into the nitty-gritty. First, what exactly is a DBMS, or database management system? This chapter is written for those with no prior experience in database development but might have used SQL or have a general understanding of databases. It explains what a DBMS does, what it consists of, and so on. While this information is relatively high-level, it's necessary to understand that a DBMS has various components like a transport layer, query processor, execution engine, and storage engine that reads data from disks into memory. As database users, we typically only think of SQL queries returning data without giving much thought to what happens behind the scenes. Understanding the components involved from the time you issue a query to when you receive the results (transport, query processor, execution engine, storage engine) is one of the goals of this chapter. For example, if you ever wonder why a SQL query is slow, you might check which query plan was executed. You may have already done this as part of performance improvement efforts. Now you have a better understanding of the "what" and "why" behind these actions. After covering the general architecture of a DBMS, we discussed three main points: First, databases are used to store data. Where this data is stored is a major consideration, with the two main options being disk-based and in-memory. We learned about the differences between these two types of DBMSs, including their operating costs, hardware requirements, and how data is affected by things like machine crashes. Understanding these differences will help you know which type of DBMS your organization uses. Second, there are different types of DBMSs. We learned about row-oriented (or column-oriented in Japanese) DBMSs like MySQL and PostgreSQL. We also covered column-oriented and wide-column storage DBMSs, and their respective differences. For some of you, this may have been the first time hearing the term "column-oriented DBMS" or "wide-column storage." I hope that you were able to take something away from the discussion.。## **Transcription**

Now we go to the second chapter to get into the details of indexes, but what are indexes?

In the Data Files vs. Index Files section, the actual data that is stored in the database is called the PostgreSQL Heap, but the data file that stores the data, and the index that is created to improve performance, are familiar to many of you.

An index file stores specific data, but it is important to understand what it is.

For example, creating an index is like a data file, and it is easier to understand if you think of it in terms of books.

For example, if you imagine a dictionary, the actual content of the book that describes the words is the data file.

For example, if you are looking up a new word like "pages", you have to flip through the pages to the letter "P" to find it.

But if you have a page index, you can skip straight to the page number.

That point is that a page index is, in itself, a different type of data.

This is something I learned when I read this section.

A book, like a dictionary, can take up several dozen to a hundred pages with an index.

So when you understand this, you can see what it really means.

For example, creating an index to improve SQL read performance is a great beginner lesson like SQL 101, but you can't just create indexes.

I think you can understand that when you consider the underlying mechanism.

For example, if you create too many indexes, you will need more disk space for the index size, and you will need to update the index itself.

For example, going back to the dictionary analogy, when you make a dictionary, you make an index.。## **Transcript**

Just like in the world of dictionaries, there are cases where new words are introduced, obsolete words are removed, and new meanings are added or updated when new editions (first edition, second edition, third edition, etc.) come out. As a result, the database also needs to be updated. Databases are the same, so every time the main body is updated, the index is also updated. Therefore, it needs to be updated. In other words, the more indexes you create, the more likely it is that the write performance will be affected. So, indexes are created to improve read performance. On the other hand, more size is required for the index, and I think this chapter helped you understand from the underlying mechanism that it has an impact on write performance. So, before we get into the underlying mechanism of DBMS, we'll talk about how DBMS works behind the scenes to get results when SQL is issued, and then there are different products out there. For example, MongoDB, Google Spanner, Bigtable, Redshift, and so on. When classifying them, there are different perspectives such as low-oriented, columnar or row-oriented, and other types of storage that are widely used. Also, what is the index, in terms of the underlying mechanism? In fact, I have read this chapter. Since this was the first time, the content was quite high-level. However, it was quite exciting. Personally, I had a few takeaways, including some new keywords. Personally, I was wondering about this. It was lightly mentioned in the book as a keyword. As recent research, the book discussed memory-based or disk-based systems, but there are quite a few papers out there on what happens when you put a DBMS on non-volatile memory (NVM). Other books also mention it, so I thought I would investigate it a little bit. Some of the participants mentioned it, but I don't know much about NVM-based DBMS at the moment, so I thought that was one of the takeaways. After all, each participant uses completely different databases. For example, I use MySQL and Bigtable in my company. Others use POSTGRES, and still others use document-based databases such as AWS DynamoDB. I also use databases that I've never heard of before, and others use DBMS in a variety of ways, such as streaming. I think it was great that the backgrounds were so diverse. So, I think everyone was able to gain a deeper understanding by making comments and asking questions based on their own experiences with the databases they normally use, as well as comparing and contrasting them with what others use. Well, one of the points where many people stumbled was that many people understood the DBMS architecture, but when it came to the use of column-oriented databases, there were discussion points about what specific use cases there are for those who were hearing the keyword for the first time. Also, what exactly is an index file? I had heard that it speeds up searches, but I think it was a good idea to get a rough idea of the layout on disk. I think it will lead into Chapters 2 and 3. Personally, I'm a little excited that front-end engineers and mobile engineers are also participating. For example, if I understand correctly, they are running something like SQLite's HABATZU on mobile. I think it would be great if we could catch up on the latest DBMS trends on each device, and what specific things to keep in mind when developing. Also, Firebase provides automatic new releases of remote databases. I would also like to check on the recent situation around there. Also, OLTP, OLAP, and HTAP were mentioned, and some people said they had looked into them. LTP is an online transaction processing database. OLAP is an online analytical processing database that is more suited for analysis and report generation. HTAP is a hybrid of the two. For example, OLTP databases include MySQL and PoSQL. OLAP databases include databases for big queries and analysis, such as Redshift. Some people thought about it in terms of which products they knew that fit into each category. That's about it. The content was not that in-depth, so I think many people found the introductory chapter of the book easy to read. Personally, I think the recording of the first session of the database internals was quite useful. I also talked about the policies for managing the book club and my own thoughts on the matter when it was first published at the end of last year. I won't repeat everything here, but one of the things I felt was good about starting this time was that, unlike the third session, we had a single time zone and a single team working in that time zone. Unlike last time, it felt like we were working as a team, and the discussion, including Discord, started to get a little more lively. Also, I got feedback like, "I knew your name from listening to the recordings of other guest participants and interacting on Discord, but it was nice to meet you face-to-face for the first time." I think it was a good idea to change the format this time. As we do multiple sessions, we will see what challenges arise. In the meantime, I think the first session went well and we got good feedback.。## **Transcript**

Also, the technical memos are quite exciting because there are already questions and comments before, and personally, I caught up with the information, and refreshed my memory by joining the discussions on the thread and exploring the new links shared on Discord. Turning to what has been helpful for me this time, I think it is effective to create a reproducible environment at hand. For example, in this session, we'll be talking about data file diagrams and index files, and going deep into the mechanism and behaviors of indexes. In order to deeply understand the topic, there are various approaches available, such as checking out the open-source implementation on GitHub for the database you use (e.g. Postgre), or trying to understand by getting GPT to write a reference implementation. Or you can run Postgre locally, make an environment with a certain free software service such as Superbase, and create tables and execute various indexes to check the execution plan. It might be effective to execute some of these steps while doing hands-on activities. The following chapters (Chapter 2 and 3) will get into the nitty-gritty of B-Tree behaviors. If you've studied data structure or algorithms, you might already have a basic understanding of the tree structure, but if not, you could try writing a Binary Search Tree (BST) in your favorite programming language. You can also try coding the node splits and node merges of a B-Tree in the LeetCode style. GPT can help you create well-balanced questions. For example, if you instruct GPT to generate an interview-styled question about node splits and node merges with a prompt that says, "I am reading about B-Tree in Database Internals and I'd like to understand it deeply", it will generate a question with an appropriate scope. Following that, you could ask it to generate code scripts in your specified programming language along with unit tests, which will help you deepen your understanding. Personally, in addition to reviewing this book, I would like to catch up with the latest information. I want to revisit papers that I've read in the past but couldn't grasp well (e.g. Spanner's paper), and also check out external papers and updated information that is not included in this book, in order to contribute to the book club's content. So, here is a brief summary of the first chapter.。**## **Transcription**

In Chapter 2, we’ll cover B-Tree Basic. First, let’s go over the basics of B-Tree. One of the goals for Chapter 2 is to understand why DBMS often use B-Tree. Both Postgres and MySQL utilize it. One goal is to understand why B-Tree is preferable for disk-based DBMS. For those reading Chapter 2, one of your goals should be to understand why B-Tree can be used for disk-based DBMS. Please keep that in mind as you read.

That's it for the fourth episode of Rhodo Tech Talk Book Club, a review of Chapter 1 of Database Internals.

Thank you. Thank you for watching.


## **基本情報**

- 公開日：2025年02月18日
- 長さ：47:41

## **要約**



## **目次**



## **文字起こし**

ウスタクとゴミちゃんのながらAI おはようございます。早川ゴミです。 ウスタクです。 この番組では、AIコンサルタントのウスタクと、生成AI頑張るぞ担当早川ゴミが、この1週間のAIニュースを簡潔に振り返ります。 感想は、ハッシュタグながらAIまで。 最近めっちゃ寒いですね。 この話から始めるのあれやな。 この1週間、いろんなツールの進化が自分の想定より早すぎて、諦め始めてます。 流れるままみたいになってます。 諦めないでください。 諦めずにウォッチしていきたいが、考えることが多すぎるんで、日々楽しく生きることを的に考えていこうと最近は思っております。 本当にね、楽しんだほうがいいですね。 幸せになったほうがいい。人類は幸せになるために生まれてきたんで、最近AIを触ってるとそれを忘れがちなんですけど、 人類は幸せになるために生まれてきたんで、お願いします。幸せになってください。 合理的な部分は多分どんどん合理的になっていくだろうから、そうじゃない部分とかね、個人的にどう幸せになっていくかとか重要だなって思いますし、 あと最近Twitterでフォローしてる人が言ってて印象的だったのが、AIに仕事を代替されるリスクよりも、友達に俺を代替されるリスクのほうが高い。 友達よりもAIのほうがおもろいやんってなって、自分じゃなくてAIと仲良くなって、俺と仲良くしてなくなったら困るって意図だと思うんですけど、 それはめっちゃ困るなって最近思いました。 でもそうですね、ネットフリックスの社内用語にブリリアントジャークっていう、要は賢いんだけど嫌な奴みたいな言葉があって、 ネットフリックスはこういう人を絶対に社内に入れないようにしてるんですね。まさにその話に近いかなと思っていて、 あんまりないかもしれないんですけど、人間性がいいっていうより賢いから世まで人が詰まってたとか、能力があるから人が詰まってたみたいな人とかは、 AIに代替されるリスクが高いんじゃないかと思います。逆にもう全然賢くもないし、お金も全く稼いでないんだけど、 ただはちゃべちゃに面白いから友達になっといたほうがいい奴みたいな奴は価値どんどん上がるなと思います。 本当そうかもしれないな、でもわかるよ。なんかまあでもこの人って言ってることあってるからちょっと時あるけどええかみたいな人ってまあまあいるじゃないですか。 なんかちょっとそういうの無理してまで関わらなくていいかもなみたいななってたりとかちょっとね人間関係も変わっていったりとかするんだろうなって思うと、 ちょっと友達だけ減らないような人でいたいなと最近強く思います。ちょっと皆さんも良かったら、 AI時代の一番の強みはなんかいい奴でいることだと思っているので、そこを磨いていけたらいいのかなと私も思っております。 そうですね本当にAI関係の人みんな同じこと言ってますね。AI時代に勝ち抜く方法はもういい奴であること。 もう全員そのAIの毎日使ってAIの進化に絶望してるからこいつらに勝てるわけないってみんな思ってるんですよね。 勝てないですよ。体力かいい奴かみたいな感じですよね、最近の。 間違いない体力かいい奴。 みんな是非筋トレと優しい心で、もしかしたら筋トレしていくと心の余裕ができてるかもしれないんで、 もしかしたら最初は体力かもしれない。なんか体力が心の余裕を生み出す施設あるんで、ぜひ皆さんでちょっと体も鍛えていきましょう。 このラジオを聴きながらちょっと腹筋かプランクでもしてください。 大事ですね。 ということで今週のピックアップニュース。一つ目がノートとGoogleの資本業務提携についてということで、 ちょうどね、ノートの株価がめちゃくちゃ上がってますね。上場くらいなんですかね。 今このあたりスタッフさん、結構最近注目してるっぽいですけどどういう感じですか。 はい、僕が今日こちら持ってきたのがあるツイートがきっかけで、 とある大学生の方のノートの記事がマッチングアプリというビッグワードで1位まで来てたんですね。 で、これとんでもないすごいことなんですよ。少しでもウェブ業界にいた方ならわかると思うんですけど、 いわゆるアフィリエイトサイトっていうのが世の中にいっぱいあります。 自分がそのサイトを紹介して、その自分の紹介したサイト経由で実際にサービスを使う人とかいたら、 それの一部をキャッシュバックでもらえるっていうのがアフィリエイト生徒なんですけれども、 これをやるためにいろんな人があの手この手を使ってたくさん記事を書いて、 Google上で検索させた時に上位に飛ばそうとしてるんですけど、 このマッチングアプリってそれのもうトップ10に入るんじゃないかってくらいのアフィリエイトの難しい領域なんですよ。 クレジットカード、脱毛、ウォーターサーバー、その辺と並ぶアフィリエイトの一番難しいところなんですけど、 それに大学生の1記事が載ってるっていうのを見て、それノートで書かれてるんです。 一応その大学生の人、僕ただの大学生かと思いきや、ちゃんとその人を読んだらノートめっちゃやってて、めっちゃ上手なんですよ。ただノート強い、ただの大学生の記事家っていうのはちょっとアレなんですけれども、 それにしても、あらゆる対策をしているSEO会社、とんでもない金額を投資している人に対して、 ちょっとシンプルノートを書いている大学生の人が勝っちゃうっていうのは、おもろいなというふうに思いました。 いやー、強いっすね、SEO。なんか、私もノート結構長らくやっていて、 たぶんノートってどっから流入してるかって見れないっすよね。 見れないですね。 そう、だから多分SEOで当たってるやんっていうのは調べたりとかしないとわかんないと思うんですけど、 でも、なんかね、私も前、なんでこんな上位にいるんだろうみたいなことは結構ありました。 なんか印象としてノート、なんかちょっと前は結構YouTubeが強かったんですよ。 なんか例えばですけど、私以前フェムテックやってたんで、 あの月経カップとか特定のその、なんか商品を取り上げて動画撮るっていうのをやってたんですけど、 なんかね、月経カップでGoogle検索すると、 トップの1スクロール分くらい、なんか私の動画がめちゃくちゃでかく出てくるみたいな時期があって、 YouTubeすげーみたいな。 てか、こんな出るとさすがにプレッシャーになるとか思うんですけど。 で、まぁそれで案の定結構流入もあったんですけど、 でも確かに、最近むしろYouTubeが上がんなくなって、 逆にノートはめっちゃ強いなって印象はすごくあります。 なんかちょっと前から下手に自分でブログとかサイト立てるより、 なんかノートでやった方がええんちゃうか、みたいな感じの空気はあった気がしますね。 そうですね、一応ノートって、ノートプロという月額8万円のプランがございまして、 そちらを使うと、あのー、直時ドメインとか入れられたりするっぽい。 あー、そうだね、そうだね。報酬向けとかをやらないですよね。 はい、チャットGPT研究所さんとかそれで使ってますね、AI業界で言うと。 で、今日ちょっと僕言いたいのは、そのノートのステマみたいになってるんですけど、 どっちかっていうと、AI時代に大事なのって一時情報なんじゃねっていう話を 持っていきたいと思っていて。 なるほど、そもそもね、このノートとGoogleの資本業務提供の話から始まってますもんね。 あー、そうですね。で、もちろんGoogleが資本入れたことでノート爆上がりしてるぜ、 しかもノートのSEO超強いぜ、やっぱGoogleが手小入れするといいんだな、 みたいなことを僕は言いたいわけじゃなくて、ちょっとそれ穿った目線だと思うんで。 案内そんなGoogleも露骨なことしないと思うんですけど。 で、要はこのマッチングアプリの大学生のものってどんな記事だったかというと、 実際に使ってみて、いろんな人と会った結果みたいな記事だったんですよ。 これってすごく貴重だと思うんですね。 要はいろんなマッチングサイトって、価格これですとか、カジュアルな出会いだったらこれですとか、 いろいろ書いてますけど、どうせその記事を書いてる人はマッチングアプリなんて使ってないわけですよ。 知らないから。 だけど、その大学生の人は自分でたくさんマッチングアプリを使って、 それをセキュラルに書いてるわけですね。 じゃあもう今後金額の比較とか特徴の比較なんて、 それこそオープンAIディープリサーチが一瞬でやってくれるわけだし、 ただのまとめサイトって本当にAIに代替されると思うんですね。 そもそもそのAIが引っ張ってくるサイトっていうのはまとめサイトだと思うんですけど、 どちらかというと、実際に自分で見て聞いて足を運んで得た情報の方は絶対にAIでは作ることはできないから、 それの価値があるんじゃないかなと思って、そこがシンプルに受けたと思うんですよね。 ただ単純にマッチングアプリの記事をノートで書いたら絶対にSEO1になるってわけじゃないと思うんで、 この一時情報の強さっていうのがいいところだったんじゃないかと思ってます。 いやー確かに。でなんかその話で言うと、あの結構ディープリサーチの話とかともつながってくるなと思っていて、 結局そのAIが引っかけてくるとか見に行く情報によってその出てくるものも結構クオリティがマチマチだってするじゃないですか。 なんか割とその、なんかカテゴリとか問いの立て方によっては、なんかそもそもなんかちょっとどうなんだこのクオリティはみたいなものしか引っかからなかった場合に、 なんかちょっとどう頑張ってもそんなにクオリティ高いもの出てこないなみたいなこともある気がしていて、 なんかそもそもなんか技術的にはすごいけどその食べる情報が何かっていうのでめちゃくちゃそのアウトプットが変わってくるし、 そういった意味で論文とかしっかりした機関が出しているようなあの硬い情報っていうのと、 もう少しその人間が体験していく前線の情報っていうのが掛け合わさるとすごく深みのあるようなアウトプットになってくるのかなっていうのはすごく思いましたね。 そうですね、もうそのまま2つ目のトピック行っちゃいますか。 ということで2つ目のトピック、ディープリサーチ出現から2週間経って何に使っているかということなんですけど、 ちょっとね、ディープリサーチどうですかという話で、ここで指しているのはChatGPTのディープリサーチのことを指してますよね。 はい。 どうですか、おスタッフさんは。 今一番使っているAIがディープリサーチですね。 もう2週間経ちましたけどずっと使ってますね。 いやまだ2週間経ってないのか。 10日間くらいしか経ってないと思うんですけど。 怖いわ。 怖いですね。 最近直近でアプリとデスクトップ版に対応したので、 外出先からスマホでもできるようになりました。 これ地味に嬉しいです。 何に使っているかというと、 結構リサーチ系はもう全部これでやってますね、深めの。 この前キャッチコピーをAAで考えたいみたいな会社さんの法人研修行ってきたんですけど 今まではどっちかって言うとブレストに使いましょうみたいな話をしてたんですが 今回このディープリサーチで強豪調査みたいなところにすごく使えましたね その化粧水のジャンルで キャッチコピーをひたすら集めてきてくださいみたいに言うと ただのその化粧品化粧水キャッチコピーまとめみたいなアサイアフィリエントサイトだけじゃなくて いろんなLPいろんな会社のホームページとか読み込んで SK-Ⅱの化粧水だったらこれとかポーラーだったらこれとか あらゆるところのものを引っ張ってくるってことをやってくれて これは相当便利だぞって思いましたねマーケターとかにとっては 結構そのマーケターとかあといわゆる会社の経営企画みたいな形 例えば他社の状況を調べる必要があったりとか あとその新規需要立ち上げの時にそもそも各業界の状況をキャッチアップしたり 例えばKPIの大枠っていうのを掴んだりみたいなものにすごく相性がいいなと思っていて 私はそのディープリサーチ万人に進められるかと言われたら うんって感じかもなと思いつつ私にめちゃくちゃ合うなと思ったのがこの1週間くらいですね でなぜならその自分の場合これまで例えば新規需要立ち上げるって時とかに そのリサーチの手が回らないので新しくバイトの子を雇ったりとかインターンの子を入れたりとかしてて なんかこういったことをリサーチしてみたいなリサーチしていたんですけど そういったものはかなりディープリサーチでやれるなという感じはしました なので具体的に言うと例えばこういった形でポッドキャストやってたりとかするんですけど このポッドキャストってどこの数字を追ったらランキングが上がるかとか どこの数字を追ったら番組として評価されるかっていうのは各その媒体のアルゴリズムによって違うんですね でこれはポッドキャストでも例えばYouTubeでもTikTokでもそれぞれが思想が違っていて 何を一番重要としているかっていうのが違うんですけど なんかこういったものをキャッチアップするのに結構これまでだと特に国内とかでポッドキャストやってる人も限られるので情報も限られてて 結構こう実際にやってる人に聞きに行って なるほどこことここ合ったらいいですねみたいな感じでやってたんですけど 結構今もディープリサーチでガーってあらかた海外の情報も含めて当たりを出してこれに対して 生の声その実際の専門家的な人に聞いて だいたい合ってるなっていうので見えてくるみたいな感じで使えるので 結構そういった意味ですごくなんだろうな 当たりをつけてなるほどって言い返すとすごく相性がいいなと思いましたね そうですね僕も新規事業最近考えてるんですけど友人とディスカッションしてる時にこれってどうなんだろうね あーちょっと今度調べとこうかで終わってた議論がこれってどうなんだろうね あーちょっと1回ディープリサーチ挟ますとくかという風にスタートして その後10分後ぐらいに見に行くとできてて あーこの数字合ってるんだなとかっていう風になるので とんでもないですよねこの今までファクトチェックとかにファクトチェックというか 具体のデータを取りに行くのに掛かってた時間っていうのをその場でスキップできて これって単純に時間とかではなく その誰かと喋ってる時にその場でどんどん議論を前に進めていくことができる これって時間以上の価値があると思うので これは面白いなという風には思いますね でごみさんのおっしゃる通りで 今これをじゃあ万人が課金しろって言われるか微妙なんですよ 僕チャットGPT自体3000円のですねプラスプロに関しては 割と少しでも知的労働をする方は使った方がいいと思うんですけど全員 私も同じです3000円はね課金した方がいいと思うんだよな 3000円はねちょっとそもそもねこのGPTのディープリサーチは割と なんだろう使い切れない人が持った場合に結構地獄を呼び出しそうな気がしていて なんか私逆にちょっとどうだろうなぁみたいな これを言語化しすぎるとストレートすぎるどうかなと思いつつ なんかこう使いこなしきれないそのGPTが本量上回っちゃってる場合に なんかこのGPTディープリサーチ使うよりは Googleの方のジェミニーディープリサーチの方がまだ暴発しづらいなっていう印象があるんで なんかちょっとやっぱりそっちを進めたい気持ちは最近はありますね そうですね3000円ですからねちょっと一部屋増やせますからね賃貸だったら3000円すれば なんかかつそのGPTのディープリサーチの場合だと結構なんか問いの立て方によっては 逆に迷走する可能性があるなというかそのなんですかね GPTの方とジェミニの方の違いとしてGPTの方だとそのバータリ的に当たった情報を元にして ちょっとその方針を変えたりとかしてリサーチの範囲広めたりとかもするんですよ だからこうなんか結構人が調べる時みたいになんか融通が効く感じでやっていくと思うんで なんか自分が想定していた以上の回答が来る可能性って全然あるしそれがすごいなと思うんですけど なんか逆にそれがそのなんだろう荒の方向に行く可能性もあり得るというか ちょっとそこを使いこなせきれないとなんかちょっと論点がずれてたりとかしてて それを本人が認識できてないとなんかあかん形で出てきちゃって でそれをさらになんか会社とかでGPTが言ってたんでみたいな感じで出す人が出てくるとちょっとなんかやかわしいなというか なんかわりとややこしいなって思ったんで であればGoogleのジェミニの方とかだと基本問いを立てたことに対してシンプルに調べてくるみたいなそういった意味で暴発しづらいし、あっち3000円で一応使えるんで、 人によってはどこまで使い切れるかなみたいなのは、 あとたぶん仕事との相性もあると思うんで、 ちょっと考えつつ使ってもいいのかなっていうのは最近思いましたね。 でも絶対使ってほしいですよね。 いわゆる検索エージェント自体は、 ディープリサーチのね、 オープンエンスかなってもジェミニの方が。 そもそも検索体験が変わりますね。 ジェミニのディープリサーチは、 ジェミニを開いてモデル選択のところから選ぶことができます。 オープンAIの方は、 ChatGPTの普通のUIのところから3万円課金すると、 検索の横に詳細な検索っていうボタンが出てくるので、 そこから使えます。 モデル選択ではなくボタンから使うっていうところで、 若干体験が違うんでお気をつけください。 しかもね、ディープリサーチって表記じゃないんかいって、 詳細な検索なんか言ってるとちょっとややこしいんで、 よかったら皆さんね、 一旦ちょっと触ってもらうで、 そこから使うか考えるっていうのは重要だと思うので、 他の人が使ってるところをYouTubeとかで見るでもいいですし、 個人的にはまず一度お試しいただけたらいいのかなと思っております。 そう、何でもそうです。 使ったほうがいい。 実際に使ってみるのと、 ただXでつぶやいてる人の通訳を見るのでは運命の差なので、 ぜひね、この使い方とかどれ使うべきかとか、 ながらAIで勉強しつつ。 そう、あのね、そうなんですよ。 ちょっとね、会社でも私結構意識してるんですけど、 ただ私が説明してるのを見るとかだけだと、 なんかね、評論家になっちゃうんですよね。 ふむふむ、分かるぞ俺は、みたいになっちゃうんで、 なんかそれよりはね、一度触ってみて、 あーって思ってほしいですね。 なんで多分こういったとこで、 ながらAIとかでこういう感じなんだなって知って、 全部を試すのはね、皆さん多分時間に限りもあるし大変だと思うんで、 あ、これは刺さったぞってやつがあったら、 ちょっとぜひお試しください。 うーん、そうですね、ちょっと話しとれるんですけど、 最近、某団体による某生成AIの資格試験を実際に受験してみたんですよ。 あ、そうなんだ、あれですね、はい。 某団体の某試験をだったんですけど、 なんかまず、個人的にはちょっと微妙だなって思っていて、 企業の、そろそろ僕みたいにAI関係で登壇する人とか、 AI推進担当の人は使うべきかもしれない、受けるべきかもしれないんですけど、 そうじゃない?ほとんどの人にとっては、 あれを受けたところで、生成AIにめちゃめちゃ使いこなせるようになるかって言われると、 ならない系の問題だったんですね。 例えば、この理論を提唱した、この機械学習の理論を提唱した人は誰ですか?とか、 その第一次AIブームとは何ですか?とか、 その機械学習の仕組みとかトランスフォーマーの仕組みについて間違っている記述はどれですか? みたいなものなんですよ。 で、個人的に一番イケてないなと思ったのが、 その全部の問題ってチャットDBで解けちゃうんですよ。 そんな全部の問題をチャットDBで解けるような試験を、 でも絶対にAIとか他の画面開かないでくださいみたいに書いてあるんですね。 ちょっとなんか本末転倒感というか、 そういう皮肉なんかはもはや。 そう、皮肉なのかと思った。 そんなチャットDBに聞けば一瞬で分かることを、 なんか人間が覚えておく必要ってあるのかなとかって思っちゃいましたね。 それが人間の仕事だよっていう政治的な主張かもしれないですけど、 でも、逆に私今ので、逆に興味湧いたのはちょっと、 なんかやらなきゃいけないなって思ったんですけど、 たぶん結局は使ってみて、 こういう感じなんだって理解するほうが早いと思ってるんで、 なんかちょっと長らいAIの初回で話したような、 なんかラビダビとかもなんでもいいんですけど、 なんかそういうのでね、触って知ったのがせせや詳しかったりするんですよ。 なんでこういうの苦手とか知ってんだろうみたいなくらい詳しかったりするんで、 まあ本当に理論はね、後からついてきまして、 たぶんやってくうちに興味湧いてくると思うんで、 なんでこんなに突然チャットDBで流行ったみたいな、 たぶん興味湧いてくると思うんで、 それはそれでね、気になったときに調べてもらって、 まあまあまずは使ってもらうのがね、一番ですね。 ほんとそうですね。 なのでよくインターネットだと、僕みたいなですね、 SNSでセンセーショナルなことを言って、 大して使ってもないのにAIの情報を発信する人のことを、 プロ驚き屋と揶揄されるわけなんですけれども、 僕はね、一応頑張って使うようにしてるんですけど、 なんかまあすごく冷笑されるんですね。 なんかああ、またプロ驚き屋さんね、みたいに言われるんですけど、 まあ実際詳しいんですよ。 その僕をはじめとしたプロ驚き屋の人たちって、 もう要は批判家みたいな名前を一切取らず、 ただひたすら触って、ひたすら発信しまくるみたいなことをやっていて、 それに対してじゃあ、ちょっとうがった目で、 なんかいやでもそれ理論が、みたいに言ってる人って、 最新のAIツールに詳しいかとか、 それを業務で使いこなせてるかって言われると、 正直僕はそんなことないなっていうふうに思っていまして、 ここのまあちょっとバランス感覚っていうのは結構難しいなと思いますね。 当然センセーショナルなことを言って、 人の不安を煽るっていうのは良くないとは思いつつも、 ただまあ自分がプレイヤーとして使ってるっていうのと、 ただSNSで見聞きした情報だけで判断するっていうのは、 全く違うんだなってことは思っていただいて、 ぜひセンセーAIは手で試していただけると嬉しいなと思います。 次のニュース。 アドビファイアフライが熱い、アドビマックス行ってきたレポ。 ということで、 ちょうどこれ収録している日の数日前にですね、 アドビマックスという、 アドビの最新情報を、アドビのフェスみたいなやつに、ちょっとPRのお仕事で行ってきたんですけど、 なんかその時私は思ったんですよ。 いや、なんか国内の生成AI驚き会話の人たち、 アドビに驚いてなくないですか?って思って、 ちょっとこれは私が責任を持って、 もともとね、私美大出身でアドビと共に生きてきたんで、 なんかこれは責任を持って私がアドビ驚き会にならなきゃいけないんじゃないかなと思ったので、 ちょっとめちゃくちゃ驚かせていただきたいというコーナーでございます。 アドビ見てますか?うすたくさん。 僕ですね、恥ずかしいこと言ってたんですけど、 人生でほぼ一度もアドビ製品を触ったことがないです。 そうやって生きていけるんですね。 そういう生き方もありますね。 普通にね、ちょっとフェアに見たとき、 私アドビの良くないところはアドビ帝国に、 まず入国して納税してないと、 このアドビについてはちょっと理解することが難しいんですよ。 大学時代にアドビの教育を受けているので、 アドビ帝国の中での生き方も理解しており、 逆にUI的にもすごく慣れていて、各ツール触れていて、 かつ、ちょうど私は去年のブラックフライデーで、 散々単プランというか、 フォトショップとか依頼とか個別プランで契約してたんですけど、 それを諦めてCCという、全部フルパッケージみたいな月、 いくらですかね、1万円弱くらいだったと思うんですけど、 そのプランに切り替えたんですよ。もう意を消して。 で、なんでこういう諸々を理解できているという前提ではあるんですけど、 そういうちょっとクローズド、いわゆる性性愛会話のオープンな感じとは全く違う文化ではあるし、 それに対して、ご意見があるのはもうめちゃくちゃ理解はしているんですけども、 当時代ということに対して私も文句がないわけではないんですけども、 ただちょっと私は去年の秋についにCCに課金したくらい、 ちょっと高いと思ってたんですよ、アドビのCCプランが。 だって月1万円くらい払ってか、年間いくらかって思ってたんですけど、 正直かなり今回のAI関連のいろいろな進化を見て、 これはむしろ安いなと思いました。 で、ちょっとこの辺で具体的に説明をしていくと、 まず昨日いろいろニュースは出て、新しいトピック出ていたんですけども、 まずビデオの生成ができるようになったっていうのは一つビッグポイントです。 そもそもちょっとアドビファイアフライについて説明しておくと、 アドビ独自のクリエイティブAIのモデルをアドビ独自で作っているというようなことでございます。 その上で一般的に画像生成とか動画生成の一番の課題って権利の話だと思うんですけど、 アドビの場合もともとその自社でフリー素材とか的な、 いろいろクリエイティブをためておくようなサービスを出していたので、 そこのその権利がフリーだというのがクリアになっているものをベースに学習をさせていて、 商用利用がフリーかつ権利に関してもかなりクリアな状態であるっていうのがこのファイアフライの特徴なんですね。 なのでかなり現場でも使いやすいっていうのが一番ポイントだと思っています。 私も結構、どういう形であれば社内でクリエイティブで使っていいかとかって判断難しいですけど、 アドビとかだと割と使いやすいよねっていうところがありまして、 画像生成もともとめちゃくちゃ良かったんですよ。 例えばですけど、もともと写真で足元切れちゃってて写ってないとかを拡張するみたいなとか、 結構いろんな使い方ができるからすごい便利で、 私コスプレとかで使ってたんですけど、 ベルトを忘れちゃった時とかにベルトとかで生成できるんですよね。 ベルトついてないけど後でベルトを生成しようみたいな。 最近ファイアフライありきのコスプレをしてるんですけど、 これは後で足した方が早いみたいな。 そのくらいすごい便利だしリアルだしめちゃくちゃいいんですけど、 それにさらに動画が出てきたので、 実際にその仕事の現場でも使っていく人が増えるんじゃないかなというのが、 そもそもアドビのこのAIについてでございます。 その上でちょっと1個踏み込んで話すのであれば、 一般的な画像生成とか動画生成との大きな違いとしては今の権利の話だったりとか、 あとそもそもクリエイティブにおいてどうやって生成AIを活用するのかっていうフローが、 本職クリエイターの方とそれ以外、 どっちかというと画像生成とか生成AIが来た人と全然違うなと思っていて、 いわゆるクリエイティブにおいて、 例えばデザイナーが生成AIを活用するときに、 ランダムに画像を生成してその中からいいやつを使うというよりは、 クライアントの要望があってこういったものを作りたいですっていうのの幹部なりを作って、 そこのここのスペースに、 この三角形のスペースに入る形の犬の画像が欲しいみたいになるわけですよね。 なんかこのここにタイトルが入るか、この隙間に入る犬の画像が欲しいみたいな。 そういったここにちょうどいいサイズの犬を入れたいみたいにすごく相性がいいUIになってるんですよね。 だからそのあたりのUI、UXを考えると、 ちょっとクリエイティブ系は、 アドビューワンチャー一人勝ちの可能性があるんじゃないかなって最近思ったという話でございます。 熱量が伝わりました。 もうそういうことです。 でもちょっと話しながら思ったんですけど、 ちょっとデザイン系の人とかでないとすごさが伝わらないのかも。一般的な広告の制作フローとかを知らないとちょっと説明がむずいですよね。 そうですね。僕も多分詳しくは全くないんですけれども、研修とかでアドビの話をされることはすごく多いですね。 自社で使っているツールがアドビなので、一応僕課金はしてるんですよ。 逆に?私がこんだけ悩んで課金したら。 とりあえず課金はして、アフターエフェクトとか一応ちょっとチラッと触ったりとか、 フォトショーとかいられとかも一応ちょっとチラッと触ったことはありつつでも、 仕事で使ったことはないんで、アドビ使えますとは全く言わないんですが、 やっぱあれですよね、僕の理解的にはスラックって優れてるけど勝つのってTeamsだよねみたいな話ですよね。 マイクロソフト製品がやっぱり会社では使われてるから。 本当にそうだと思います。 今話して思ったのは、コーパイロットの専門家コンサルとかあるけど、 アドビかけ生成AIの驚き屋専門としてやっていこうかなって思うくらい、 多分一部界隈では極めてニーズは高いなって思いました。 髪砕いて話すのであれば、普段の業務フローに組み込みやすいっていう話だと思います。 提供価値も極めて普段の業務フローに組み込みやすい形のツールを提供している。 かつ、このアドビ圏内の独特なUIがあるんですね。 アドビ圏内だとツール間の互換性もあるし、 例えば私の場合、フォトショートいられとかいくつかのツールは元々使ってたんですけど、 アフターエフェクトを大学時代に触ったことなくて、 でも突然アフターエフェクト始めても大体どれが何か分かんないですね。 アイコンとかが一緒なんで、アドビ言語があるんですよ、その中で。 その中で触れるってこと自体もかなり価値はあるなって思いましたし、 あと是非課金されているスタッフさんにお勧めしたいのは、 アドビプロジェクトネオというものが、 ちょうど昨日日本語版に対応したのかな。 昨日というか2月13日に日本語版に対応したと思うんですけど、 これが生成やLLMが乗っかっているツールで、 例えば丸の3D空間で丸っこいオブジェクトを置いて、 2つ丸っこいオブジェクトを置いて上に三角形を乗せたら、 一応雪だるまをイメージしてその3つのオブジェクトを配置することができるじゃないですか。 それに対して寒い雪空の中で高校と照らされている雪だるまみたいな感じで プロンプトを入力すると、その適当な丸、 全体2つプラス三角錐が雪だるまとして画像だったり生成されるんです。 画像というか、生成されるみたいなツールが出まして、 これは私は結構感動したので、 こういう形で普段の作業に掛け算の形で、 LLM、生成AI機能が搭載されていくというのはすごく魅力的だなと思いますし、 多分この調子だと色々すごいスピードでツールが出ていくと思うので、 ちょっと噛み砕いて私もこのながらAIとかで何か話す機会を持てたらなと思いました。 でないと何かね、このAdobeだけ驚き屋不在で進み、 何かいつの間にかすごいことになってるやみたいになりかねないんで、 ちょっと私はね、未来出身として責任を持って驚いていきたいと思いましたという感じでございます。 そうですね。国内でAIの活用事例がなかなか広まないので、 驚き屋の属性に合ってるかどうかってすごくありますよね。 それこそオープンAIシリーズとか、あとはみんな基本驚き屋の人ってベンチャー企業なんで、 Google製品とかに搭載されるとみんなすぐに使って発信ができるんですけど、 一方でマイクロソフト製品のコパイロット、コパイロットスタジオとかコパイロットエージェントとかいないですよね。 あんまりそもそも僕なので珍しいのでポジション的にあそこ張ったりしてるんですけど、 Adobeもその大体デザイン系ってFigmaとCanvaでやるよねとか、 動画編集、ファイナルカットプロとかキャップカットとかでいいよねとかっていう風になっちゃってるので、 あんまりAdobe知らないんですよ、僕も含めて。 なので広まんないですよね、AI活用事例が。 別に使われてないとかじゃなくて、発信者の属性。 しかも使われてるかもちょっと私怪しいなと思ってて、 私Adobeありがちだなって思うのが、ぬるっと新機能が増えてくるんですよ。 これは別に生成AI以前から。 こんなツールあった?みたいなの結構あって、 例えばですけど、Dimensionかな?ちょっと名前も曖昧なんですけど、 パッケージ、例えばペットボトルに対してこの画像を映し込んで、 パッケージのMockというんですかね、イメージ画像を作るみたいなことができるツールとかがあって、 私マジで半年前から初めて知って、こんなのあったらもっと最初から使ってたんだなって思ったんですね。 結構そういうことがすごく多いんで、そもそもぬるっと増えてくんですよ。 これはぜひデザイナーの方にもっと使ってもらって、 いろいろ事例が出てきたらいいなって思いますし、 そこの橋渡しは私ができたらいいなと思っているので、 またちょっと継続的に共有させていただきます。 いいですね。Adobe専門発信者、受けますね。オープンAの最新情報とか全部チャットGPT研究所が出すんで 確かに。チャットGPT研究所アドビス視点として分店でやろうかな ちょっと今度乗れん訳の相談をしておきます 何訳すぎんね。チャットGPTでもないしね、そうなるとね チャットGPT研究所アドビス視点って意味わかんないです。AI研究所なの私 ちょっと別の発信手法を考えておきます オープンAI、新型AIを数ヶ月以内に提供、モデルを一本化ということで この新型モデルの話も気になるんですけども、新型AIの話も気になるんですけども 私がそれ以上に今回注目したいなと思ったのが、どうやらモデルが一本化するという事で これはどういった事かと言いますと、現在GPT4Oっていう数字が先に来てOが後ろに来るものと Oが先に来て、例えばO1みたいな、O1、O3みたいな、Oが先に来るものと 実は2種類あるんですね。より一般的なユースに適しているものと もう少し専門的な感じみたいな、ざっくりイメージだと 書いてありますね、わかりやすく ちょっと待ってくださいね、これは日経新聞の記事にわかりやすくまとまっているんですけど 幅広い質問や指示に素早く答えるGPTから始まるGPTのシリーズと 数学など複雑な問題に時間をかけて答えるのが得意なOの2種類のモデルがあると これ今まで実は違うスタンスというか形でユーザーが選ばなきゃいけなかったですけど どうやらこれが別に1個で良くねっていう話になるかもみたいな感じのことを 告知されていたというような感じですね 良かったですよ、わかりやすくなって 本当ね、ネーミングって大事ですからね ネーミングを単純に変えるっていうより そもそもの概念の話だとは思うんですけれども 結構AI界隈どんどん新しくなるんで どんどんリブランディングとかも変わっていってるんで いつの間にか名前変わってるみたいなことすごいありますね あるんですよね、それめっちゃ思う いいですよね、今この4OとO1、O3ミニ、O3ミニハイ、O1ミニもあるし 一応3.5も4も使えるし、4Oミニも使えるし こうすると研修でどれ使い分けたらいいですかってすごい質問くるんですよ 聞かれる、答えてます 基本的にはわかんなければ4Oで大丈夫です ちょっとわかってきて 4Oよりそんなに賢くなくていいタスクだなと思った時は 4Oミニを使ってくださいっていう風に答えて 課金されている方だったら ちょっとより日本語の精度深掘りたいとかだったら O1プロ使ってください 無課金の人だったらO3ミニ使ってください 4と3.5はほぼ使わなくて大丈夫です みたいな説明してますね いやーでも本当にそうですね あとねなんかそもそもじゃあ GeminiとCloudとGPTどれがいいですかって話もあって 2段階でややこしいじゃないですか そもそもどれにすんのっていう その会社間の話もありつつ さらにそこん中のどのモデルにするのってややこしいんですけど 正直よほど専門的な使い方をしないのであれば なんかViveサーナもしくは大手のオープンAIなり Googleなりのやつ使ってもらって その中で一番メジャーなGPTの場合だと4Oですね を一旦使ってくれっていうのが 本当に現在の最適解なんじゃないかなとは思ってますね うん冷静に そりゃそう僕もチャットGPT3.5から使ってるんで なんとなく理解できてますけど 普通に今じゃあ新しくAI始めようってなってた人が そもそもGeminiでもGemini1.5Pro 1.5Flash 2.5Proでエクスペリメンタルとか クロードモンス3.5Sonnet エクスペリメンタルって何? クロードモンス複数ストレートやって でチャットGPTではね その0.1.0.3みたいな話もあれば コードインタープリターって何? キャンバスって何? プロジェクトって何? とかソラってどっから使うの? オペレーターってそもそも何なの?とかっていう風になって 名前が多い 複雑やすぎないかと思いますね 思うしかもなんかその 何だろう数字のやつとさ名前があったりするじゃん そのSonnetって何みたいな なんかそのさ数字で表記する人と 名前で表記する人がバラけしたりとかしててさ もうなんか説明がややこしいんで 一旦もうね見ないでくださいって思った 社内とかで相談されても ちょっと一旦忘れてくださいって思ってます 一旦もういいよGPT4を使ってっていうのが正直なとこなんで まあまあこれがあのちょっとシンプルになっていくっていうのは すごく一般のユーザーのまずエントリーの時に大事ですし あと結構ありがちなのがそのモデルの表記よくわかんないから ちょっとマイナスとか使って 使えないじゃんってなるみたいなとか なんかそのもう少し緩い利用なのに なんか大モデル使って遅いじゃんってなるみたいな なんか結構そういうこう不要なすれ違いは減ったらいいなと思ってるので まあシンプルになるのはいいなと思いつつ まあプラスもう一個で言うとその 新型AI数学説以内に提供みたいなのがなんかしれっと出てスピード速すぎてもどうしよう、どうしようって思ってます。 5が出たら、完全に3から始まって4が出て5のわけなので、一応最大級のアップデートですよね。 4が出たのが、そろそろGPG3.5が出てから結構数ヶ月、2023年の頭ぐらいだったと思うんですけど、4が出たのって。 そこから2年ぐらい一応間が空いたわけなので、これはとんでもない、その進化が早すぎるなっていう感じですね。 でも、これが4を4.5で全部GPG5になったらめっちゃわかりやすいんで、ちょっと僕もピチャイに伝えときます。 お前のとこ1.5プロとか2.5分かりづらいから、ジェミにスゴオソとか、ジェミにビミョハヤとかそういう風に変えとけって、ちょっとピチャイとサムに伝えときます。 誰?誰? LINEで。 LINEやってんすか?LINEやってんすか?おもろすぎるだろ。 伝えたほうがいいですよ。そうなんだよね。私もジェミに大変好きだし、ジェミにの場合は数字がでかくなりゃいいっていうので、比較的はわかりやすくはあるんですけど、私が一番ちょっとややこしいなって思ってるのは、バーテックスAIってあるじゃないですか、ちょっと法人向けの方とかAPIとかで表記がめちゃくちゃあふれてる感じが私はしていて、 なんか生成AI関係のAPI多分2,3種類くらいあるじゃないですかね、名前違いで。結局これがそれぞれ何なのかあんま調べてもよくわかんなくて、ちょっとGoogleに関しては数字とかモデルの表記は全然今の感じで、日付が入ったりエクスペリメンタル入ったりしてちょっとわかりづらいんですけど、まあまあまだ許容範囲な気がしており、 それよりかちょっとそのAPIとかの法人の方の表記がすごいわかりづらいんで、なんかそっちをそのジェミに法人向けとかなんかわかりやすくしてほしい。 おだしょー APIの名前が、ジェミニ1.5プロとか、その2024とかじゃなくて、ジェミニ法人向けって書いてあるんですかね。 大平 ジェミニティブランゲージAPIみたいなのがあるんですよ。で、それとVertex APIが違うんじゃなかったか、なんかね結構APIがGoogleクラウド内でいくつか表記があって、それがちょっとよくわかんないんで、 生成AIなんでもAPIとかにしていただけたらこちらとしては大変助かるなと。もうオールAIみたいな、法人AI、APIみたいなちょっとわかりやすくなってほしいなっていうのは個人的な希望でございますね。 おだしょー そうですね、一応前にエンジニアの友達に教えてもらったのが、だったかの結果あるんですけど、今って何か開発しようと思った時に、クラウドのAPIとジェミニAPIとオープンAPIって3つ入れないといけないじゃないですか。 それを全部1個のサイトに1個のサイトのAPIに課金したら、そのAPIに突っ込んだら全部のモデル使えるみたいなのが一応あるんですよ。 今の議論だと、そろそろモデル名わかりづらいから直せみたいな話は若干違うんですけど、一応そういう便利なものもできたりするんで、この辺のAPIわかりづらい問題は、ある程度決定版みたいなLLMが出れば決まると思いつつ、そんなものは出ないというか、どんどん進化するので難しいなとは思いますね。 ちょっと当面苦しむんだろうなと思っております。そんな感じでね、今週もいろいろ話していきましたが、なんかこの調子だと本当に数週間後にはGPT4.5が出る可能性もなんかありますし、ちょっとながらAIも忙しくなりそうですね。 さすがにGPT5が出たら、ちょっと緊急で動画を回していますみたいなやりますよ。緊急でポッドキャストを撮っていますみたいなやるんで、この場合は豪快として出します。 おもろいですね。今緊急で一足回してるんですけど、じゃなくて、今緊急でポッドキャストやってます。 全然緊急じゃなさそうですよ、ポッドキャストが急に。 ポッドキャストはね、でも早く出せるはずなんで、その時はBGMもなしで緊急感を高めて出そうと思うので、その時はぜひ聴いてください。 うん、間違いないです。 最後に、こちらの番組は毎週月曜日の朝に配信していく予定です。 ぜひ聞き逃さないように番組をフォローください。 感想はハッシュタグながらAI。ながらがひらがなのAIが英語です。まで。 で、よかったらこちらの番組のレビューだったりとかが、ポッドキャストSpotifyだったりAppleでできますので、そちらもぜひぜひお寄せください。 それが私たちのやる気につながっております。 皆さんのおかげで、前回の2、3日くらい前にですね、国内15位まで来まして、細野源のポッドキャストの、細野源のオールナイトニッポンの上でした。 おもろすぎるな。 いや、本当にね、皆さんが聞いてくださったおかげですし、こんなにね、ハッシュタグで感想いただけると思ってなかったので、 ちょっとポッドキャストいつもやる気が出ない私なんですけど、ちょっと久々にやる気を感じております。 これは頑張ろうと思っているので、ぜひぜひお寄せください。 ということで、それでは皆さんまた来週お会いしましょう。バイバイ。 さよなら。

## **English Transcription**

## 

Good morning, Dust and Wuster-chan, leaving AI to do the work for us. I'm Gomi Hayakawa. This is Wuster. On this program, AI consultant Wuster and I, Gomi Hayakawa, work for the betterment of generative AI, as we briskly reflect on AI news from this past week. For comments, please use the hashtag, "leaving AI to do the work for us." It's been super cold lately. That's a weird way to start a conversation. This past week has been a little overwhelming because various tools are evolving more quickly than I had expected, and I'm beginning to get discouraged. I feel like I'm just going with the flow. So don't give up.。**## **Transcription**



I want to continue watching without giving up, but there’s so much to think about, so lately, I’ve been thinking that the objective should be to live each day happily. It’s true, it’s best to have fun. It’s best to be happy. Humanity was born to be happy, but I often forget that these days when I’m working with AI. Humanity was born to be happy, so I’m asking you. Please be happy. The logical parts will most likely continue to become more logical, so I think it’s important to focus on the parts that aren’t, like how to personally become happier. Also, something a person I follow on Twitter recently said left an impression on me: The risk that my work will be replaced by AI is lower than the risk that my friends will replace me. It’s like saying that AI is more interesting than friends, becoming friends with the AI rather than me, and then feeling bad once I’ve disappeared. It’s something I’ve come to think is really bad. But yeah, there’s an internal term at Netflix called “brilliant jerk,” which basically means someone who’s smart but unpleasant. Netflix makes a point of never hiring such people. I think it’s similar to that idea; it may not happen much, but I think the types of people who have poor character but are popular because they’re smart or because they’re capable are at high risk of being replaced by AI. On the flip side, the types of people who aren’t particularly smart, don’t earn much money at all, but you want to be friends with them simply because they’re so much fun to be around, I think their value will continue to rise.。## **Transcription**

I guess that's true, but I understand. You know, there are people who say the right things, and there are times when it's okay to let them be. Like, I think it's better to let go of those kinds of relationships rather than forcing it, and I think that human relationships will change a little. I've been thinking more and more lately that I want to be the kind of person who doesn't lose friends. Everyone, please know that I believe the greatest strength of this AI era is being a good person, and I think it would be good if we could all develop that part of ourselves. Yes, that's right. Everyone involved in the AI industry says the same thing. The way to survive the AI era is to be a good person. Everyone is using AI every day and despairing over its evolution, so everyone thinks it's impossible to win over them. You can't win. It's like it's all about physical strength or being a good guy these days. That's for sure, physical strength or being a good guy.。## **Transcription**

Everyone, please work out and be kind. Perhaps as you work out, you will gain mental余裕余裕 (余裕, headroom), or perhaps it will initially be physical stamina. In any case, there is a facility where physical stamina produces mental headroom, so let's all work on building our bodies a bit. Please do some sit-ups or planks while listening to this radio broadcast. It's important. So, this week's featured news. First, regarding the capital business partnership between Note and Google. Incidentally, Note's stock price has been rising a lot. Is it about to go public? The staff around here seem to have recently taken quite an interest. How do things look? Yes, the reason I brought this with me today is because of a tweet, which led to an article about Note by a university student reaching number one in the trending topic "matching app." This is an incredible thing.。## **Transcription**

As people who have been in the web industry will probably understand, there are a lot of so-called affiliate sites out there in the world. When someone introduces the site, and through their introduction people actually use a service, part of that is received as cash back—that's what an affiliate student is. People use every trick in the book to write lots of articles, and try to have them show up at the top when people search on Google. This is one of the most difficult areas of affiliate marketing, maybe even in the top 10. It's as difficult as credit cards, hair removal, and water servers. Then I saw an article written by a university student, and it was written in a notebook. At first I wondered if this was just an ordinary university student, but when I read what the person had to say, I realized that they were writing a lot of notes and they were very good. It's not just that they had a lot of notes, it's that they were a great writer. But still, for a university student to beat out SEO companies taking all kinds of measures, and people who are investing outrageous sums of money, is funny. Yeah, SEO is powerful. I've been taking notes for a long time, and I guess there's no way to see exactly where your traffic comes from. You can't see it. That's why, even if you investigate, it might not be clear that you're getting hits because of SEO. There have been a lot of times in the past when I've wondered why I was ranking so high. In my impression, it used to be that YouTube was pretty strong.。## 

For example, I used to do femtech and I made videos introducing menstrual cups and specific products, but when you Googled "menstrual cup," my videos would show up huge on the top of the first scroll. I thought, "Wow, YouTube is amazing." But then I thought that it would be a lot of pressure if I kept showing up like that. And sure enough, I got a lot of traffic, but recently, YouTube has stopped showing my videos, while Note has become really strong. I've noticed that recently, instead of setting up your own blog or website, it's better to do it on Note. Also, Note has a monthly plan called Note Pro for 80,000 yen. If you use that, you can add a custom domain. Oh, right. Right. You don't use it for advertising or anything. Yes, the ChatGPT Research Institute uses it for that. In the AI industry, that is. What I want to say today is that it's like a Note advertisement, but I want to talk about how ephemeral information is important in the age of AI. I see. After all, this all started with the story of Note and Google's business investment.。## 

Oh, yes. Of course, I'm not trying to say that Google's investment has caused a huge increase in the number of notes and that Google's SEO is strong, and it's good to have Google's support. I think that's a bit of a cynical perspective. I don't think Google is doing anything that obvious.

So, what kind of article was this college student's experience with matching apps? It was an article about the results of actually using the apps and meeting different people. I think this is very valuable.

The thing is, many matching sites just list prices or say that they're for casual encounters. But the people who write these articles don't actually use matching apps. They don't know.

However, this college student used many matching apps and wrote about them from a secular perspective. So, in the future, I think that AI will be able to do things like compare prices and features very quickly. I think that simple summary sites will be replaced by AI. I think that the sites that AI pulls from are probably summary sites.

But I think that information that is actually obtained by someone who has seen, heard, and visited the sites themselves cannot be created by AI. I think that's what makes it valuable, and I think that's why it was well received.。## 

I don't think that simply writing an article about a matching app in a notebook would definitely rank first in SEO. I think the strength of this ephemeral information was probably a good thing.
Oh, indeed. And speaking of that, I think it also connects to the discussion about deep research. After all, the quality of the information that the AI brings up or the information that we go to see varies quite a bit depending on the information that the AI brings up. In fome cases, depending on the category or how the question is phrased, only results of questionable quality may be displayed. I feel like no matter how hard we try, sometimes it's not possible to get high-quality results. I feel like the technology is amazing, but the quality of the output depends on the information that is fed into it. In that sense, I think that combining hard information, such as academic papers or information from reputable organizations, with more experiential information from the front lines can lead to very insightful output.
That's right. Should we move on to the second topic straight away? So, the second topic is what we have been using deep research for two weeks since its appearance. Could you tell me a bit about how you are using deep research? When we say "deep research" here, we are referring to ChatGPT's deep research, right?
Yes. How do you use it, staff members?
I'm using deep research the most right now. It's been two weeks, but I've been using it all the time.。## 

It hasn't even been two weeks yet? I thought it was only about 10 days. This is scary. It's scary, isn't it?

Recently, it has become compatible with the app and desktop versions, so you can now also use it on your phone when you're out and about. This is surprisingly convenient. What do I use it for? I already do all the in-depth research with this, pretty much. The other day, I gave a corporate training session to a company that wanted to create a catchphrase using AA. Until now, the discussion had been more about brainstorming, but this time I was able to use it effectively for deep research on strong competition. For example, when I ask it to collect all the catchphrases for a certain brand of lotion, it doesn't just summarize catchphrases from affiliate sites for that brand of lotion, it also reads through various landing pages and company websites. For example, it pulls out things like this for SK-II lotion, this for Polar, and it brings together information from all over the place. I thought this was incredibly convenient, especially for marketers. It's also compatible with tasks like the marketing planning that companies do. For example, when you need to research the status of other companies or when you need to catch up on the status of each industry when creating new demand. I think it's perfect for things like getting a general idea of KPIs. If you were to ask me if I would recommend deep research to everyone, I would probably say yes, but I think it's been a great fit for me personally for the past week or so. Why? Because in my case, when I'm trying to create new demand, I don't have time to do research, so I've been hiring part-timers or interns to do it for me. I've been thinking about doing this kind of research, and I feel like deep research can do it. To be specific, I do things like host podcasts. For each medium, the algorithm is different, so the numbers that you need to chase in order to rank or to be evaluated as a program are different. You need to know what is most important to each medium, whether it's a podcast, YouTube, or TikTok, for example. Up until now, there were limits on the information available, especially in Japan, because there are limits on the number of people doing podcasts. You often had to go ask someone who was actually doing it and say something like, "I see, so it would be good to combine this with this." But now, I can use deep research to quickly gather most of the information, including overseas information, and then I can check it with an actual expert in the field. It's almost like it can show me what's right. So, in that sense, I think it's a great match.

That's right. I've been thinking about a new business with a friend recently, and when we were discussing it, we would often end up saying things like, "I wonder what this is about" or "Oh, I'll look into it later." But now, we can start by saying, "I wonder what this is about" and then quickly use deep research. Then, after about 10 minutes, we can check it and see that it's done, and we can see if the numbers match. It's amazing, isn't it? Up until now, we've been skipping the time it takes to do fact-checking or to gather specific data on the spot. It's not just about saving time; it's about being able to move discussions forward on the spot while talking to someone. I think that's worth more than time, so I think it's interesting.

But as Mr. Gomi says, it's not clear whether everyone should pay for this right now. As for me, I think that everyone who does any kind of intellectual work should use ChatGPT Plus, which costs 3,000 yen. The same goes for me. I think everyone should pay 3,000 yen for it. I feel like this deep research in GPT is something that can create chaos if it's not used properly. On the other hand, I wonder if I'm being too straightforward. I think that if you can't use GPT properly and it exceeds the volume, then I have the impression that it's less prone to accidents if you use Google's Gemini deep research instead of GPT deep research. So, lately, I've been feeling like I should recommend that.

That's right. It's 3,000 yen, so you can add a room if you're renting. If it's 3,000 yen, you can... However, if you ask questions a certain way when using GPT deep research, it may go astray. What's the difference between GPT and Gemini? With GPT, it can change its approach based on the information it acquires by barter, and it can also expand the scope of its research. So, I think it does things in a way that's flexible, like when people do research. So, there's a possibility that you'll get answers that you didn't expect, and I think that's great. On the other hand, it's also possible that it will go in a strange direction. If you can't use it properly, it may miss the point or something, and if the person doesn't realize it, it may come out in a bad way. If someone then says something like, "GPT said this, so..." at a company, it's a little ambiguous and confusing. On the other hand, Google's Gemini is less likely to go astray because it basically searches for simple answers to questions. It also costs 3,000 yen to use, so depending on the person, it depends on how much they can use it. I think it also depends on the compatibility with your work, so I think it's a good idea to use it while thinking about these things.

But I definitely want people to use it. As for search agents themselves, Deep research... Even if it's an open source, Gemini...。## 

Okay, first of all, the search experience is different. Gemini's deep research can be used by opening Gemini and selecting the model you want. For OpenAI, after paying 30,000 yen from the regular ChatGPT UI, there will be a button for "Detailed Search" next to the search box. You can use deep research from there. Please note that the experience is slightly different because you use a button instead of selecting a model. Also, the term "deep research" is not used. It's called "Detailed Search," which can be a bit confusing. I'd like everyone to try it out first to decide if you want to use it from there. You can watch others using it on YouTube, or you can just try it out for yourself first. That's what I personally recommend. The same goes for anything. It's better to use it yourself. There is a huge difference between actually using it and just listening to someone talk about it on Twitter. So, while you're using it, learn about the usage and which one to use. That's right. That's the thing. I'm very conscious of this at work, but if you just listen to me explain it, you become a critic.。## 

Hmm, I think I understand, but rather than just understanding it intellectually, I think it would be better to try it out first and see how it feels. Because I think this is the kind of thing where you need to actually experience it to understand how it works with while AI and all that. And I know everyone has limited time, so you can't really try everything, but if you find something that resonates with you, I encourage you to give it a try. Well, it's a bit of a tangent, but I recently took a qualification exam from a certain organization on a certain generative AI, and..

Oh! You did? Yes, yes, I know the one you mean. 

So I took that exam, and my personal feeling is that it was a bit questionable. I think people who are already in AI-related fields, or who are in charge of promoting AI in their companies, might need to take it. But for most people, it's not going to make you an expert in using generative AI. The questions were more like, "Who proposed this theory of machine learning?" and "What was the first AI boom?" and "Which of the following is an incorrect description of the mechanism of machine learning or transformers?"

And the thing that I found most disappointing was that all of the questions could be answered using a chat database. They even had it written on the exam that you couldn't use AI or open any other screens, but... It felt a bit like the cart before the horse, or maybe even a bit ironic. Yes, I thought it was ironic。## 

I wondered if it was really necessary for humans to memorize things that we could get from such a chat DB in an instant. It might be a political argument that it's a human's job, but conversely, I've become a bit more interested in it, and I think I might use it, and come to understand what it's like. I think it's quicker to just try it out, rather than talking about how AI might be in the long term, like I did the first time. I think it's better to actually touch and learn about it, like Lavidadee. I end up knowing more about why I'm bad at something. It's like I already know because the theory is just coming after it. I think you'll get more interested the more you use it. It's something that I'll probably get curious about myself. Of course, it's best to just use it when you're curious and interested. It's easy. On the internet, there are people like me who sensationalize things on social media and give information about AI that they haven't even properly used—they're called "professional quacks." I personally try to use it properly, but I often get criticized. I'm told, "Oh, there's a professional quack talking again." I'm actually quite knowledgeable. Most of us "professional quacks" don't get any credit for what we do—we just delve into AI, and just keep putting out information. Our critics will give us the side-eye and say, "Yeah, well your theory is..." but when you ask them if they know about the latest AI tools or if they're actually using them in their work, I don't think they are. I think the balance is really hard to strike. Of course, it's not good to just sensationalize something and scare people, but I think there's a big difference between using the tool yourself and judging it only by what you see on social media. I hope everyone gives this AI tool a try. Next news: Adobe Firefly takes off—a report from Adobe Max.。## **Transcription**

So, just a few days before the day I was recording this, I went to Adobe MAX, which is like an Adobe event. I went there for a PR job, and at that time, I thought to myself, "Hmm, aren't the people in Japan who are surprised by generative AI also surprised by Adobe?"

I felt a sense of responsibility because I graduated from art school and have always used Adobe products. So, I thought I should take responsibility and become a person who promotes and talks about the amazing things Adobe has to offer. Are you guys at Adobe watching? I'm a big fan.

I'm embarrassed to admit this, but I've almost never used Adobe products in my entire life. It's possible to live like that. It's a possible way of life.

To be fair, when I look at it objectively, Adobe has a bit of an empire. It's hard to understand Adobe if you haven't entered its empire and started paying taxes.

I received Adobe training in college, so I understand how to navigate the Adobe empire. I'm also very familiar with the UI and have used all of the tools.

Last Black Friday, I subscribed to individual plans for Photoshop, Illustrator, etc. I eventually gave up on that and switched to the CC plan, which is like a full package that costs around 10,000 yen per month. I finally subscribed to CC last fall, but I always thought the CC plan was a bit expensive.。## **Transcription**

I thought it was about 10,000 yen per month, and I wondered how much it would cost per year, but honestly, after seeing the various evolutions of AI related to this time, I thought it was rather cheap. Let me explain in a concrete way. First of all, there was a lot of news yesterday, and a new topic came up. First, the ability to generate videos is a big point. First of all, let me explain about Adobe Firefly. It is an Adobe-owned model of creative AI created by Adobe itself. On top of that, I think the biggest issue with general image and video generation is the rights issue. However, Adobe had already provided a service that stores various creative works, including free materials, so the learning was based on the fact that the rights for those materials were cleared. The fact that it is free for commercial use and fairly clear in terms of rights is the characteristic of this Firefly. So I think the biggest point is that it is easy to use in the field. It's hard for me to judge how to use it creatively in a company, but with Adobe, it's relatively easy to use. Image generation was also very good. For example, extending a photo that originally had a person cut off at their feet, etc. It can be used in many different ways, so it's very convenient. I used it for cosplay, such as when I forgot my belt. You can generate a belt or something like that. You don't have to wear a belt, but you can generate one later. Recently, I've been doing cosplay with Firefly, but I think it would be faster to add it later. It's that convenient, and it's so real and wonderful, so I think it will be used by more people in the actual work field. That's all about Adobe's AI.。## 

If we delve a bit deeper, the major difference from common image and video generation is the current copyright issue. Also, the flow of how to utilize generative AI for creative purposes is completely different between professional creators and others. Namely, when using generative AI for creative purposes, for example, when a designer uses generative AI, rather than randomly generating images and choosing the best ones, they create a framework based on the client's request and what they want to create, and then they may want a dog-shaped image that fits in a triangular space in a specific area. They may want a dog image that fits in this gap, with a title here. The UI is very compatible, as it allows you to insert a dog of the perfect size. Therefore, when considering the UI and UX, I recently thought that the creative field may be dominated by Adobe One Venture. I hope you understand my enthusiasm. That's what I mean. However, as I was talking, I realized that people who are not involved in design may not understand the significance. It may be a bit difficult to explain without knowing the general workflow of advertising production. That's right. I don't think I know much about it either, but I often hear about Adobe in training sessions.。## 

I pay for it since my company uses Adobe tools. On the contrary? What if I paid for it after struggling this much? I paid for it and tried After Effects and Photoshop, and Illustrator, but I've never used it for work. I can't say I can use Adobe at all, but my understanding is that Slack is great, but Teams is the winner, right? Because Microsoft products are used in companies after all. I totally agree. With me talking now, there's expert consultation with Copilot, so I think there is a high demand for Adobe's generative AI as an expert. When talking in a more detailed way, I think it's about being easy to incorporate into the daily workflow. The value provided is to provide tools in a form that is easy to integrate into the daily workflow. Also, there is a unique UI within this Adobe ecosystem. Within the Adobe ecosystem, there is compatibility between the tools. For example, I used some tools like Photoshop and Illustrator, but I never touched After Effects during my college days. If I suddenly started After Effects, I wouldn't know what most of it is.。## **Transcription**

Since it's integrated with icons and all, there's this Adobe language within it. I thought it was pretty valuable just to get exposure to it. And another thing I'd like to recommend to staff who are being billed is Adobe Project Neo, which just recently became available in Japanese yesterday, I think. Or rather, it became available in Japanese on February 13th. It's a tool with generative AI and LLM. For example, you can place round objects in a 3D sphere, then place two round objects on top of a triangle, and you can arrange the three objects to resemble a snowman. Then, when you enter a prompt like "a snowman lit by a streetlight in a cold, snowy night," an image of a snowman using those circles—the two round ones plus the triangle—is generated. Or rather, this is a tool that generates images. I was pretty impressed by it, so I think it would be really appealing if LLM and generative AI functions could be added as multipliers to our usual work. And at this rate, I think all sorts of tools will be coming out at an amazing speed, so I'd like to have the opportunity to talk about these things in more detail as they come along. Otherwise, Adobe will continue to move forward without anyone to express surprise, and before we know it, it will be doing amazing things. So, as someone from the future, I feel a sense of responsibility to be surprised. I guess you could say that's how I feel. That said, it's true that AI use cases aren't really spreading in Japan, so I wonder if I'm really cut out to be the "surprised one." When it comes to people who are generally surprised by things like the OpenAI series, they're usually folks at venture companies. So, when something gets added to a Google product, everyone starts using it right away and talking about it. But on the other hand, there's no Microsoft Copilot, Copilot Studio, or Copilot Agent, right? Maybe it's because I'm a freelancer, but I'm not familiar with those things. Adobe is also mostly about design, so people tend to stick with Figma and Canva. For video editing, they use Final Cut Pro or CapCut. So, not many people know about Adobe, including me.。## **Transcription**

That's why AI usage cases don't spread much. Not because they are not being used, but because of the sender's attributes. In addition, I'm a little suspicious that they may actually be used. I think Adobe has a knack for adding new features smoothly. This has been the case even before generative AI. For example, there were quite a few tools like, "Has anyone ever used this tool?" For example, was it Dimension? I'm not sure about the name, but there are tools that allow you to project an image onto a package, such as a plastic bottle, and create an image of what the package would look like. I only found out about it half a year ago, and I thought, "If I had known about this, I would have started using it a long time ago." This happens quite often. In the first place, it increases smoothly. I would like to see more designers use it, and I think it would be great if more cases came out. I hope I can bridge the gap, and I will continue to share it on an ongoing basis. That sounds good. Adobe Specialist Sender is a good idea. The OpenA update information and everything else is provided by the Chat-GPT research institute.。**## Transcription**

From the perspective of Chat-GPT researcher, I'll contact the branch office and talk it over. Let's not depend on them too much. And it's not even Chat-GPT, so that makes no sense. I'm from Chat-GPT Research, an AI research institute. I'll think of a different way to spread the information.

OpenAI, a new AI, within a few months, as a model consolidation. I'm interested in this new model, but even more interested in the new AI. What I'm most interested in is that the model will be consolidated. What does this mean? Currently, there are two types: one with the number GPT40 where the O comes after the number, and one where the O comes first, like O1 or O3.

One is more suitable for general use and the other is more specialized. That's a rough idea. Wait a minute. This Nikkei newspaper article summarizes it nicely:

There are two types of models: the GPT series, which starts with GPT and can quickly answer a wide range of questions and instructions; and the O series, which excels at answering complex problems such as mathematics, but takes more time.

Until now, users had to choose between these two different stances or forms, but it seems like they're saying that it might be better to have just one.

It's great if it becomes easier to understand. Naming is really important. I think it's more than just changing the name. It's about the concept itself. The AI field is constantly evolving, so rebranding and other changes often happen. Sometimes the name changes without us even noticing.

Yes, that's true. There's so many now: 40, O1, O3 mini, O3 mini high, O1 mini. And 3.5 and 4 are still available. I often get asked about which one to use for training.

I answer that you can basically use 40 if you don't know. If you understand it a little and think the task doesn't require something as smart as 40, then use 40 mini. 

If you're paying for it and want to explore Japanese accuracy, use O1 Pro. If you're not paying, use O3 mini. You don't really need to use 4 and 3.5.

But yes, it's true. And then there's the question of which is better: Gemini, Cloud, or GPT. It's already confusing with two levels. First, there's the question of which company to use. Then, there's the question of which model to use within that company.

Honestly, unless you're using it for something very specialized, I think the easiest solution right now is to use what Vive サーナ or a major company like OpenAI or Google provides. With GPT, the most popular one, use 40 for now.

Yeah, that's the calm and rational thing to do. Of course, I've been using Chat-GPT 3.5 since the beginning, so I understand it to some extent. But for someone who's just starting out with AI, it's too confusing with Gemini 1.5 Pro, 1.5 Flash, 2.5 Pro, Experimental, Cloud Monst 3.5 Sonnet, Experimental, multiple Claude Monst straight, etc.

And then with Chat-GPT, there's 0.1.0.3, etc. What's a code interpreter? What's a canvas? What's a project? Where do you start with Sora? What is an operator? etc. There are so many names, and it's too complicated.

I think it's too complicated. What's the point of having numbers and names? Sonnet, for example. Why is it called that? Some are represented by numbers and some by names, and it just makes the explanations more complicated.

For now, I think we should just ignore it. If someone asks me about it at work, I'll tell them to forget about it for now. Just use GPT4. That's the honest truth.

It's important for general users to have a simple entry point. And I think it's quite common for people to get confused about the model notation and end up using something that doesn't work, or using a large model when a smaller one would do. I hope this simplifies things and reduces unnecessary misunderstandings.

But on the other hand, I'm also a little worried about the speed at which the new AI will be released. What if it comes out too soon?

If 5 comes out, it will be a major update, as it will be the third to fifth version. 4 came out a few months after GPG 3.5, around the beginning of 2023. So there was about a two-year gap. This is incredibly fast.

But if 4 becomes 4.5 and then GPG 5, it will be much easier to understand. I'll pass that on to Pichai. Tell him that the 1.5 Pro and 2.5 versions are confusing, and he should change them to something like "Great Gemini" and "Slow Gemini". I'll pass that on to Pichai and Sam.

Who? Who? On LINE.。## 

Do you use LINE? Do you use LINE? That's hilarious. You should tell him. That's right. I also really like Gemini, and in the case of Gemini, it's relatively easy to understand because the numbers are bigger, but the thing I think is a little confusing is that there's Vertex AI, right? I feel like the表記 for法人向け and APIs is really excessive, and there are probably 2 or 3 different APIs related to generative AI, but with different names. I've tried researching what each of these actually does, but I still don't really understand. As for Google, the表記 for numbers and models is still the same as it is now, with dates and experimentals, which is a little confusing, but I think it's still within the realm of acceptability. More than that, though, the表記 for APIs and things like that is really confusing, so I'd like Gemini to make those easier to understand for法人向け.

Odasho: The API name is not Gemini 1.5 Pro or something like that, but is it written as Gemini For Business?

Ohira: There's something called Gemini Text Language API. And that's different from Vertex API, isn't it? There are actually several different ways to表記 APIs within Google Cloud, which is a little confusing. So if they could just make all AI-related APIs the same, that would be a big help to us. I personally hope that they could make it a little easier to understand, like "All AI" or "Business AI API".

Odasho: Right. A while ago, I was told by an engineer friend that when you want to develop something now, you have to include three things: cloud API, Gemini API, and open API.。## 

There's a way to charge all of the models to a single API on a single site, and then you can put all of the models into the API and use them all at once. The current discussion is slightly different, like the model names are hard to understand, so we should fix that. But there is a convenient thing that can be done, so the problem of the API being hard to understand will probably be resolved once we have a finalized version of LLM, but it seems that we won't have such a thing. They will continue to evolve, so it will be difficult. I think we will continue to struggle for a while. Anyway, we've talked about a lot of things this week, and it seems like GPT4.5 may actually come out in a few weeks, so even AI will be getting busy. When GPT5 comes out, I'll definitely make an emergency video about it. I'll do an emergency podcast about it, and I'll release it as a special episode. It's so funny. I'm doing an emergency run right now, or rather, I'm doing an emergency podcast right now. The podcast doesn't sound urgent at all, though. I mean, we should be able to release the podcast quickly, so when we do, I'll try to heighten the sense of urgency by removing the background music, so please listen to it when it comes out.。**Transcription**

All right, you got it, guys. And finally, for those wondering, this show is going to be a weekly podcast airing every monday morning. Make sure you follow the show so you don't miss an episode. Your feedback is welcome by hashtag nagara AI. Nagara in hiragana, AI in English. to. And if you feel so inclined, please feel free to review the show on podcasting platforms like Spotify or Apple. Your support really motivates us. Thanks to you all, just a few days ago, we managed to climb to number 15 in the country. Even above the Hosono Gen podcast, on Hosono Gen's All Night Nippon. That's hilarious.。## 

Well, really, it's thanks to everyone who has listened, and I never thought so many people would share their thoughts with hashtags, so I'm feeling motivated, even though I don't always feel up to doing my podcast. But I'm feeling motivated again for the first time in a while. So I'm going to make an effort, so please keep your feedback coming. And with that, I'll see you all again next week. Bye-bye. Goodbye.

